#!/bin/bash
#
# aursync
#
# Updates a repository stored in S3 and notifies of any package updates
#

exec 2> >(tee "/cmd_errors.log" >&2)
set -Euo pipefail

err_report() {
    local parent_lineno="$1"
    local message="$2"
    local code="${3:-1}"

    echo "err_report for aursync"
    if [[ -n "$message" ]]; then
        echo "$0: ${parent_lineno}: $message; exiting with ${code}" >> /err.log
    else
        echo "$0: ${parent_lineno}; exiting with ${code}" >> /err.log
    fi
    # Prepend the latest error message to the log
    printf '%s\n%s\n' "$(tail -1 /cmd_errors.log)" "$(cat /err.log)" > /err.log

    /send-pushover "Build Error" "$(cat /err.log)"
    exit ${code}
}

trap 'err_report ${LINENO} "${BASH_COMMAND}" $?' ERR
IFS=$'\n\t'

remote_path=${REMOTE_PATH}                                  # Location within S3
repo_name=${REPO_NAME}                                      # Name of the repo (the DB file)
region=${AWS_REGION}                                        # AWS region
local_path=$(echo $remote_path | sed 's|s3:/||g')           # Location stored within the container
aur_key=${AUR_KEY}                                          # Name of GPG signing key within AWS parameter store
aur_keys=${AUR_KEYS}                                        # Name of public keys within the parameter store
bucket=$(echo $local_path | sed 's|/\(.*\)/.*|\1|g')        # Name of the bucket

mkdir -p "$local_path"

# Import the required GPG keys
aws ssm get-parameter --region "${region}" --name "${aur_key}" --with-decryption | jq -r ".Parameter.Value" > aur.key
sudo -u makepkg gpg --import aur.key
gpg --homedir /etc/pacman.d/gnupg --import aur.key
GPGKEY=$(sudo -u makepkg gpg --show-keys --keyid-format LONG aur.key | grep sec | grep -o -P '(?<=/)[A-Z0-9]{16}')
rm aur.key
pacman-key --lsign-key "${GPGKEY}"

# Also import public keys used to verify some packages
sudo -u makepkg gpg --recv-keys $(
    aws ssm get-parameter \
        --region ${region} \
        --name ${aur_keys} |
        jq -r ".Parameter.Value" |
        sed 's/,/\n\t/g'
)


echo "Sync remote DB to local"
aws s3 sync \
    --region ${region} \
    --acl public-read \
    --exclude "*" \
    --include "*files.tar.zst" \
    --include "*db.tar.zst" \
    ${remote_path}/ ${local_path}/

ln -sf "$repo_name.db.tar.zst" "$local_path/$repo_name.db"
ln -sf "$repo_name.files.tar.zst" "$local_path/$repo_name.files"


echo "Add repo to pacman.conf"
cat >> /etc/pacman.conf << EOF
[${repo_name}]
Server = file://${local_path}
SigLevel = Optional TrustAll
EOF
pacman -Syy


pkgs=$(aur repo -Su -d $repo_name)
echo "Upgrading packages"

# Get any dependencies that are within the local repo
#TODO: Can probably replace this by having a remote and local repo
pkg_names=$(aur repo -Su -d $repo_name | awk '{print $1}')
for pkg in $pkg_names
do
    echo "Pulling dependencies for ${pkg} in local repo"
    deps=$(comm -12 <(aur depends $pkg | awk '{print $2}' | sort) <(aur repo -a | awk '{print $1}' | sort))
    for dep in $deps
    do
        echo "Pulling ${dep} as a dependency of ${pkg}"
        aws s3 sync \
            --region ${region} \
            --acl public-read \
            --exclude "*" \
            --include "$dep*" \
            ${remote_path}/ ${local_path}/
    done
done

sudo chown -R makepkg:users "$local_path"
sudo -u makepkg aur sync -S --no-view -d "$repo_name" --root "$local_path" -u --noconfirm || true
failed_pkgs=$(aur repo -Su -d $repo_name)


# Clean up unnecessary packages
OLDIFS=$IFS
IFS=' '
echo "Removing packages in the official repo"
official=$(pacman -Sl | grep -v "$repo_name" | cut -d' ' -f2 | sort)
personal=$(aur repo -r "$local_path" -d "$repo_name" -l | awk '{print $1}' | sort)
packages_to_remove=$(comm -12 <(echo $official) <(echo $personal))
IFS=$OLDIFS

sudo -u makepkg repo-remove "$local_path/$repo_name.db.tar.zst" $packages_to_remove -s

echo "Cleaning up old packages..."
old_files=$(aws s3 ls "$remote_path/" | awk '{print $4}' | grep pkg.tar.zst | grep -Fvf \
    <(tar --exclude="*/*" --zstd -tf "$local_path/$repo_name.db.tar.zst" 2>/dev/null | sed 's|/||g') || true)

for file in $old_files; do
    aws s3 rm \
        --region ${region} \
        "$remote_path/$file"
    rm "$local_path/$file"
done


echo "Sync local DB to remote"
aws s3 sync \
    --region ${region} \
    --acl public-read \
    --follow-symlinks \
    ${local_path}/ ${remote_path}/


echo "Notify of built packages"
for pkg in $pkgs
do
    echo "${pkg}"
    msg_status=""
    if [[ $failed_pkgs =~ $pkg ]]; then
        msg_status="Failed update for"
    else
        msg_status="Updated"
    fi

    IFS=' '
    read -ra ADDR <<< "$pkg"
    IFS=$'\n\t'

    pkg_name=${ADDR[0]}
    pkg_ver="${ADDR[1]} -> ${ADDR[3]}"

    /send-pushover "${bucket}: ${msg_status} ${pkg_name}" "${pkg_ver}"
done

